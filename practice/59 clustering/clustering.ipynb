{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый пункт, который предлагается выполнить в рамках домашнего задания, имеет объявленную \"цену\" в баллах. Максимально возможная сумма – 10 баллов, а с учётом бонусных пунктов – 12 баллов. Выполнять все пункты не обязательно, можно сделать только часть. В большинстве пунктов ожидается, что вы напишете работающий код на Python; иногда надо будет писать комментарии в свободной форме – например, сравнивать несколько подходов к решению одной задачи. Там, где оставлены пустые клетки под ваши ответы, вы можете по своему усмотрению добавлять ещё клетки.\n",
    "\n",
    "* * *\n",
    "\n",
    "Эта лабораторная работа посвящена кластеризации. Мы будем работать с рукописными изображениями цифр, научимся их кластеризовать двумя разными методами (иерархическая кластеризация и алгоритм $K$-means), оценивать качество разбиения и выбирать оптимальное число кластеров, а также визуализировать промежуточные результаты.\n",
    "\n",
    "# 1. Получение данных\n",
    "\n",
    "Данные, с которыми мы будем работать, доступны в библиотеке scikit-learn (модуль называется `sklearn`) в подмодуле `datasets` через функцию, которая называется `load_digits`. Всего имеется 1797 наблюдений, каждое из них представляет чёрно-белую картинку 8 $\\times$ 8 пикселей. Эти картинки – распознанные рукописные цифры от 0 до 9. Образцов написания каждой цифры дано приблизительно поровну, около 180.\n",
    "\n",
    "Для удобства использования данных каждая картинка \"развёрнута\" в строку, так что NumPy-массив, в котором хранятся данные, имеет размерность 2 и величину 1797 $\\times$ 64 (а не, например, размерность 3 и величину 1797 $\\times$ 8 $\\times$ 8). Интенсивность цвета в каждом пикселе кодируется целым числом от 0 до 16.\n",
    "\n",
    "Кроме наблюдений (картинок), известны соответствующие им значения целевой переменной: какую цифру на самом деле изображает каждая картинка. Мы могли бы сразу сформулировать задачу обучения с учителем и предсказывать цифры по картинкам, но для целей этой лабораторной работы мы будем действовать по-другому: сделаем вид, что нам не известны истинные метки классов (т. е. цифры) и даже количество классов, и попробуем сгруппировать данные таким образом, чтобы качество кластеризации оказалось наилучшим, а затем посмотрим, насколько точно полученные кластеры совпадают с группами изображений одинаковых цифр.\n",
    "\n",
    "**(0.5 балла)** Загрузите данные. Добейтесь, чтобы в переменной `X` оказался массив наблюдений, содержащий 1797 $\\times$ 64 числа, а в переменной `y` – массив истинных меток классов, содержащий 1797 чисел.\n",
    "\n",
    "*Указания:*\n",
    "- Как загрузить данные, объяснено в справке к функции `load_digits`.\n",
    "- Размер массива хранится в атрибуте `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Визуализируйте первые десять картинок, расположив их на сетке 3 $\\times$ 4 (в последнем ряду останутся пустые места). Добейтесь, чтобы фон картинок был белым, а изображения цифр – тёмными.\n",
    "\n",
    "*Указания:*\n",
    "- Не забудьте импортировать NumPy и Matplotlib.\n",
    "- Картинки 8 $\\times$ 8 можно либо достать готовыми из объекта, загруженного функцией `load_digits`, либо сделать самостоятельно из строк массива `X`. Во втором случае пользуйтесь методом `reshape`.\n",
    "- Чтобы изображение не было цветным, можно вызвать функцию `plt.gray`, прежде чем начать рисовать.\n",
    "- Располагать картинки на сетке умеет функция `plt.subplot`. Ознакомьтесь со справкой к ней.\n",
    "- По умолчанию число 0 кодирует чёрный цвет, а число 16 – белый цвет. Подумайте, как обратить цвета одной операцией над NumPy-массивом.\n",
    "- Выводить картинку на экран умеет функция `plt.imshow`. Ознакомьтесь со справкой к ней.\n",
    "- Если считаете нужным, можете отключить сглаживание – параметр `interpolation` у функции `plt.imshow`.\n",
    "- Если считаете нужным, можете отключить деления на координатных осях. За это отвечают функции `plt.xticks` и `plt.yticks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(12,8))\n",
    "\n",
    "for x, d, ax in zip(X, y, axes.flat[:-2]):\n",
    "    ax.set(title=d, xticks=[], yticks=[])\n",
    "    ax.imshow((16-x).reshape((8,8)), cmap='gray')\n",
    "    \n",
    "for ax in axes.flat[-2:]: fig.delaxes(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Кластеризация и оценка качества\n",
    "\n",
    "Мы будем использовать два популярных алгоритма: иерархическую кластеризацию и метод $K$ средних ($K$-means clustering). Эти и другие алгоритмы кластеризации доступны в библиотеке scikit-learn в подмодуле `cluster`. Иерархическая кластеризация называется `AgglomerativeClustering`, а метод $K$ средних – `KMeans`.\n",
    "\n",
    "Интерфейс у большинства алгоритмов в scikit-learn простой и единообразный:\n",
    "- Чтобы инициализировать модель, нужно создать экземпляр соответствующего класса со всеми необходимыми параметрами. Например, у кластеризаций единственный обязательный параметр называется `n_clusters`, это количество кластеров, которое мы хотим получить на выходе.\n",
    "- Инициализированную модель можно обучить, вызвав метод `fit`.\n",
    "- С помощью обученной модели можно предсказывать, вызывая метод `predict`.\n",
    "\n",
    "Как видно, этот интерфейс хорош только для задач обучения с учителем, в которых чётко разделены фазы обучения модели и предсказания с её помощью. У кластеризаций зато есть метод `fit_predict`, который разбивает входную выборку на кластеры и сразу же возвращает результаты разбиения.\n",
    "\n",
    "**(0.5 балла)** Используя каждый из двух методов, иерархическую кластеризацию и $K$ средних, получите разбиение массива `X` на 10 кластеров.\n",
    "\n",
    "*Указания:*\n",
    "- Оба раза должен получиться массив из 1797 чисел – номеров кластеров.\n",
    "- `KMeans` делает несколько (по умолчанию 10) запусков со случайными центрами и из полученных разбиений выводит лучшее в терминах среднего внутрикластерного расстояния. Чтобы улучшить качество предсказаний, можно увеличить число запусков, например, до 100. Это параметр `n_init` в конструкторе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=10, n_init=100)\n",
    "clusters = km.fit_predict(X)\n",
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = AgglomerativeClustering(n_clusters=10)\n",
    "clusters = ac.fit_predict(X)\n",
    "clusters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Визуализируйте центры кластеров, полученных каждым из двух способов. Это опять должны быть картинки на сетке 3 $\\times$ 4 с белым фоном и тёмными контурами. Прокомментируйте: какой из двух алгоритмов даёт центры кластеров, больше похожие на типичные начертания цифр?\n",
    "\n",
    "*Указания:*\n",
    "- Центр кластера – это среднее по всем наблюдениям, входящим в кластер, т. е. по какому-то набору строк из `X`.\n",
    "- Чтобы выбрать наблюдения, входящие в кластер номер `i`, используйте индексацию по булевозначной маске. Саму маску можно получить из массива предсказанных номеров кластеров и числа `i` оператором `==`.\n",
    "- Усреднять NumPy-массив вдоль какой-нибудь из осей умеет функция `np.mean`. Ознакомьтесь со справкой к ней. Нам нужно усреднение по строкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((181, 64), (181,))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[clusters == 0].shape, y[clusters == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(12,8))\n",
    "\n",
    "for c, ax in enumerate(axes.flat[:-3]):\n",
    "    counts = np.bincount(y[clusters == c])\n",
    "    digit = np.argmax(counts) # most common\n",
    "    ax.set(title=digit, xticks=[], yticks=[])\n",
    "    x_center = X[clusters == c].mean(axis=0)\n",
    "    ax.imshow((16-x_center).reshape((8,8)), cmap='gray')\n",
    "\n",
    "for ax in axes.flat[-3:]: fig.delaxes(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ситуации, когда истинное число кластеров неизвестно, подбирают оптимальное число кластеров. При этом учитывают две величины: внутрикластерное расстояние (чем меньше, тем лучше) и межкластерное расстояние (чем больше, тем лучше). Так как две эти величины не достигают оптимума одновременно, обычно оптимизируют какой-нибудь функционал от них. Один популярный функционал называется \"силуэт\" (silhouette). Вот как он вычисляется.\n",
    "\n",
    "Пусть $X$ – множество наблюдений, $M \\subset X$ – один из кластеров, на которые оно разбито в результате кластеризации, $\\rho$ – метрика на $X$. Выберем какое-нибудь одно наблюдение $x \\in M$. Обозначим $a(x)$ среднее расстояние от $x$ до точек $x'$ из того же кластера:\n",
    "$$\n",
    "a(x) = \\frac{1}{|M| - 1} \\sum_{x' \\in M,\\, x' \\ne x} \\rho(x,\\, x')\n",
    "$$\n",
    "\n",
    "Обозначим $b(x)$ минимум средних расстояний от $x$ до точек $x''$ из какого-нибудь другого кластера $N$:\n",
    "$$\n",
    "b(x) = \\min_{N \\ne M} \\frac{1}{|N|} \\sum_{x'' \\in N} \\rho(x,\\, x'')\n",
    "$$\n",
    "\n",
    "Силуэт – это разность межкластерного и внутрикластерного расстояний, нормированная до отрезка $[-1,\\, 1]$ и усреднённая по всем наблюдениям:\n",
    "$$\n",
    "\\frac{1}{|X|} \\sum_{x \\in X} \\frac{b(x) - a(x)}{\\max(a(x),\\, b(x))}\n",
    "$$\n",
    "\n",
    "В scikit-learn силуэт считается функцией `silhouette_score` из подмодуля `metrics`. На вход нужно передать массив наблюдений и результат кластеризации.\n",
    "\n",
    "**(1.5 балла)** Для числа $K$ от 2 до 20 включительно получите разбиение массива `X` на $K$ кластеров каждым из двух методов. Посчитайте силуэт. Посчитанные значения силуэта сохраните в переменную и визуализируйте в виде графика в координатах: число $K$ – значение силуэта. При каком числе кластеров достигается максимум силуэта?\n",
    "\n",
    "*Указания:*\n",
    "- Не забудьте, что функция `range` не захватывает правый конец диапазона.\n",
    "- Под значения силуэта можно завести два списка: один для иерархической кластеризации, другой для $K$ средних.\n",
    "- Рисовать графики умеет функция `plt.plot`. Ознакомьтесь со справкой к ней.\n",
    "- На одной картинке можно разместить несколько графиков, это просто несколько последовательных вызовов `plt.plot`.\n",
    "- Чтобы добавить легенду (подписи к графикам), можно воспользоваться функцией `plt.legend`. Местоположение легенды контролируется параметром `loc`.\n",
    "- Чтобы подписать координатные оси, можно воспользоваться функциями `plt.xlabel` и `plt.ylabel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда известно \"правильное\" (в каком-нибудь смысле) разбиение на кластеры, результат кластеризации можно сравнить с ним, используя такие меры, как однородность (homogeneity), полнота (completeness) и их среднее гармоническое – $V$-мера. Определения этих величин довольно громоздкие и основаны на понятии [энтропии распределения вероятностей](https://ru.wikipedia.org/wiki/Информационная_энтропия); подробности излагаются в [этой статье](http://aclweb.org/anthology/D/D07/D07-1043.pdf). На практике достаточно знать, что однородность, полнота и $V$-мера заключены между нулём и единицей – чем больше, тем лучше.\n",
    "\n",
    "Так как мы знаем, какую цифру на самом деле изображает каждая картинка (это массив `y`), мы можем использовать однородность, полноту и $V$-меру для оценки качества кластеризации. Функции для вычисления этих величин доступны в scikit-learn, в подмодуле `metrics`, под названиями `homogeneity_score`, `completeness_score`, `v_measure_score`. Как вариант, можно использовать функцию `homogeneity_completeness_v_measure`, которая возвращает сразу тройку чисел.\n",
    "\n",
    "**(1 балл)** Повторите предыдущее задание, используя $V$-меру вместо силуэта. При каком числе кластеров достигается максимум $V$-меры?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Снижение размерности признакового пространства\n",
    "\n",
    "Иногда, особенно когда признаков много и не все они одинаково информативные, бывает полезно снизить размерность признакового пространства, то есть вместо $d$ исходных признаков перейти к рассмотрению $d' \\ll d$ новых признаков. Данные были представлены матрицей $n$ наблюдений $\\times$ $d$ исходных признаков, а теперь будут представлены матрицей $n$ наблюдений $\\times$ $d'$ новых признаков.\n",
    "\n",
    "Есть два популярных подхода к снижению размерности:\n",
    "- отобрать (select) новые признаки из числа имеющихся;\n",
    "- извлечь (extract) новые признаки, преобразуя старые, например, сделать $d'$ различных линейных комбинаций столбцов исходной матрицы $n \\times d$.\n",
    "\n",
    "Одним из широко используемых методов извлечения признаков является сингулярное разложение матрицы (singular value decomposition, SVD). Этот метод позволяет сконструировать любое число $d' \\le d$ новых признаков таким образом, что они будут, в определённом смысле, максимально информативными. Математические детали сейчас не важны; познакомиться с ними можно, например, [здесь](https://www.coursera.org/learn/mathematics-and-python/lecture/L9bCV/razlozhieniia-matrits-v-proizviedieniie-singhuliarnoie-razlozhieniie)\n",
    "(по-русски) или [здесь](https://www.youtube.com/watch?v=P5mlg91as1c) (по-английски).\n",
    "\n",
    "В scikit-learn есть несколько реализаций сингулярного разложения. Мы будем использовать класс `TruncatedSVD` из подмодуля `decomposition`. В конструктор этого класса достаточно передать один параметр `n_components` – желаемое число новых признаков. Метод `fit_transform` принимает матрицу и возвращает новую матрицу с таким же количеством строк, как прежде, и количеством столбцов, равным числу новых признаков.\n",
    "\n",
    "<u>Замечание:</u> Сингулярное разложение матрицы $M$ обычно пишут в виде $M = U \\Sigma V^{*}$, где $U$, $\\Sigma$ и $V$ – некие матрицы с хорошими свойствами. То, что возвращает алгоритм `TruncatedSVD`, – это сколько-то (сколько мы хотим получить) первых столбцов матрицы $U$.\n",
    "\n",
    "**(1.5 балла)** Выполните сингулярное разложение матрицы `X`, оставляя 2, 5, 10, 20 признаков. В каждом случае выполните иерархическую и $K$-means кластеризацию преобразованных данных (число кластеров примите равным 10). Посчитайте значения силуэта и $V$-меры. Удалось ли при каком-нибудь $d'$ получить силуэт и / или $V$-меру лучше, чем на исходных данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другая популярная техника снижения размерности, которая особенно хорошо подходит для работы с картинками, – это алгоритм t-distributed stochastic neighbor embeddings, сокращённо tSNE. В отличие от сингулярного разложения, это преобразование нелинейное. Его основная идея – отобразить точки из пространства размерности $d$ в пространство размерности 2 или 3 (обычно 2, то есть на плоскость) таким образом, чтобы как можно точнее сохранить расстояния. Математические детали есть, например, [здесь](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding), но они нетривиальны.\n",
    "\n",
    "В библиотеке scikit-learn реализацией tSNE является класс `TSNE` в подмодуле `manifold`. В конструктор можно передать параметр `n_components`, а можно и не передавать: по умолчанию он равен 2. Метод `fit_transform` работает аналогично тому, как и у `TruncatedSVD`.\n",
    "\n",
    "<u>Замечание:</u> В последние годы вместо tSNE на практике часто используется [UMAP](https://github.com/lmcinnes/umap), более быстрый алгоритм с похожими свойствами. В этой лабораторной работе не предлагается использовать UMAP, так как это потребовало бы установить ещё одну зависимость -- библиотеку `umap-learn`. Желающие могут проделать задания на tSNE с использованием UMAP; в этом случае обратите внимание на параметры `n_neighbors` и `min_dist`, которыми определяется вид проекции.\n",
    "\n",
    "**(0.5 балла)** Выполните tSNE-преобразование матрицы `X`, оставив 2 признака. Визуализируйте данные, преобразованные таким образом, в виде точечной диаграммы: первый признак вдоль горизонтальной оси, второй признак вдоль вертикальной оси. Подсветите разными цветами группы точек, соответствующих разным цифрам.\n",
    "\n",
    "*Указания:*\n",
    "- Точечную диаграмму умеет рисовать функция `plt.scatter`. Ознакомьтесь со справкой к ней.\n",
    "- За цвета точек отвечает параметр `c` у функции `plt.scatter`. Передать в него надо истинные метки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Для tSNE-преобразованных данных с 2 признаками выполните иерархическую и $K$-means кластеризацию (число кластеров примите равным 10). Посчитайте значения силуэта и $V$-меры. Удалось ли получить силуэт и / или $V$-меру лучше, чем на исходных данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла)** Для самого лучшего разбиения, которое вам удалось получить (на ваше усмотрение, лучшего в терминах силуэта или $V$-меры), опять визуализируйте картинками центры кластеров. Удалось ли добиться, чтобы каждый кластер соответствовал какой-нибудь одной цифре?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Итоги, бонус\n",
    "\n",
    "**(1 балл)** Напишите в свободной форме, какие выводы вы сделали из выполненной работы. Ответьте, как минимум, на следующие два вопроса:\n",
    "- Какой из двух методов даёт более осмысленные кластеры – иерархическая кластеризация или алгоритм $K$ средних? Зависит ли это от настроек каждого алгоритма? От критериев оценивания качества?\n",
    "- Удаётся ли улучшить качество кластеризации, снижая размерность признакового пространства?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Бонусные 2 балла)** Скачайте датасет [MNIST Handwritten Digits](http://yann.lecun.com/exdb/mnist). Как сделать это с помощью scikit-learn, написано [здесь](http://scikit-learn.org/stable/datasets/index.html#downloading-datasets-from-the-mldata-org-repository). MNIST Handwritten Digits – это 70 тысяч распознанных рукописных изображений цифр, каждое размером 28 $\\times$ 28 пикселей. Попробуйте прокластеризовать этот датасет и добиться как можно лучших значений силуэта и $V$-меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
