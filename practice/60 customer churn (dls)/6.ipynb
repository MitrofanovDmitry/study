{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "manufactured-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "established-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'ClientPeriod',\n",
    "    'MonthlySpending',\n",
    "    'TotalSpent'\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    'Sex',\n",
    "    'IsSeniorCitizen',\n",
    "    'HasPartner',\n",
    "    'HasChild',\n",
    "    'HasPhoneService',\n",
    "    'HasMultiplePhoneNumbers',\n",
    "    'HasInternetService',\n",
    "    'HasOnlineSecurityService',\n",
    "    'HasOnlineBackup',\n",
    "    'HasDeviceProtection',\n",
    "    'HasTechSupportAccess',\n",
    "    'HasOnlineTV',\n",
    "    'HasMovieSubscription',\n",
    "    'HasContractPhone',\n",
    "    'IsBillingPaperless',\n",
    "    'PaymentMethod'\n",
    "]\n",
    "\n",
    "target_col = 'Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "proud-retro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef_: 0.000 (min), 1.780 (max), 11 / 47 (zeros)\n",
      "roc_auc_score (valid):  0.8629709339998148\n",
      "roc_auc_score (test):  0.858039433490697\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(data, train=False):\n",
    "    period_bins = [0,2,5,10,17,25,33,43,53,62,70,72,100]\n",
    "    data['ClientPeriod'] = data.groupby('HasContractPhone')['ClientPeriod'].apply(lambda x: x.replace(0, x.median()))\n",
    "    data['ClientPeriodG'] = pd.cut(data['ClientPeriod'], bins=period_bins).astype(str)\n",
    "    return data\n",
    "\n",
    "data = prepare_data(pd.read_csv('./train.csv'), train=True)\n",
    "train_valid_data, test_data = train_test_split(data, test_size=0.2, stratify=data[target_col], random_state=42)\n",
    "train_data, valid_data = train_test_split(train_valid_data, test_size=0.25, stratify=train_valid_data[target_col], random_state=42)\n",
    "\n",
    "feature_cols = cat_cols + ['ClientPeriodG']\n",
    "feature_cols = list(set(feature_cols) - set(['Sex','HasPartner','HasDeviceProtection']))\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "lr = LogisticRegression(C=0.4, penalty='l1', solver='liblinear', random_state=42)\n",
    "model = Pipeline([('ohe', ohe), ('clf', lr)])\n",
    "model.fit(train_data[feature_cols], train_data[target_col])\n",
    "\n",
    "c = np.abs(model['clf'].coef_)\n",
    "valid_probas = model.predict_proba(valid_data[feature_cols])[:,1]\n",
    "test_probas = model.predict_proba(test_data[feature_cols])[:,1]\n",
    "print(f'coef_: {c.min():.3f} (min), {c.max():.3f} (max), {(c==0).sum()} / {len(c[0])} (zeros)')\n",
    "print('roc_auc_score (valid): ', roc_auc_score(valid_data[target_col], valid_probas))\n",
    "print('roc_auc_score (test): ', roc_auc_score(test_data[target_col], test_probas))\n",
    "\n",
    "data = prepare_data(pd.read_csv('./test.csv'), train=False)\n",
    "submission = pd.read_csv('./submission.csv')\n",
    "submission['Churn'] = model.predict_proba(data[feature_cols])[:,1]\n",
    "submission.to_csv('./my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "adult-rental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef_: 0.006 (min), 1.009 (max), 0 / 15 (zeros)\n",
      "roc_auc_score (valid):  0.8646116819402019\n",
      "roc_auc_score (test):  0.8591270943256503\n"
     ]
    }
   ],
   "source": [
    "def get_target_rates(data, cat_cols, target_col):\n",
    "    return {c: data.groupby(c)[target_col].mean().to_dict() for c in cat_cols}\n",
    "\n",
    "def map_target_rates(data, cat_cols, target_rates):\n",
    "    return data[cat_cols].apply(lambda x: x.map(target_rates[x.name]))\n",
    "\n",
    "def prepare_data(data, train=False):\n",
    "    \n",
    "    data['TotalSpent'] = pd.to_numeric(data['TotalSpent'], errors='coerce')\n",
    "    data['TotalSpent'] = data['TotalSpent'].fillna(0)\n",
    "    data['TotalSpent'] = data.groupby('HasContractPhone')['TotalSpent'].apply(lambda x: x.replace(0, x.median()))\n",
    "    data['ClientPeriod'] = data.groupby('HasContractPhone')['ClientPeriod'].apply(lambda x: x.replace(0, x.median()))\n",
    "    \n",
    "    period_bins = [0,2,5,10,17,25,33,43,53,62,70,72,100]\n",
    "    spent_bins = [0,18.8,198.2,679.1,1400.55,2754.3,4917.8,8684.8]\n",
    "    data['ClientPeriod'] = pd.cut(data['ClientPeriod'], bins=period_bins).astype(str)\n",
    "    data['TotalSpent'] = pd.cut(data['TotalSpent'], bins=spent_bins).astype(str)\n",
    "    \n",
    "    rates_cols = cat_cols + ['ClientPeriod','TotalSpent']\n",
    "    if train: prepare_data.target_rates = get_target_rates(data, rates_cols, target_col)\n",
    "    data[rates_cols] = map_target_rates(data, rates_cols, prepare_data.target_rates)\n",
    "    return data\n",
    "\n",
    "data = prepare_data(pd.read_csv('./train.csv'), train=True)\n",
    "train_valid_data, test_data = train_test_split(data, test_size=0.2, stratify=data[target_col], random_state=42)\n",
    "train_data, valid_data = train_test_split(train_valid_data, test_size=0.25, stratify=train_valid_data[target_col], random_state=42)\n",
    "\n",
    "redundant_cols = ['Sex','HasPartner','HasDeviceProtection','MonthlySpending']\n",
    "feature_cols = list(set(cat_cols + num_cols) - set(redundant_cols))\n",
    "\n",
    "sc = StandardScaler()\n",
    "lr = LogisticRegression(C=1, penalty='l1', solver='liblinear', random_state=42)\n",
    "model = Pipeline([('sca', sc), ('clf', lr)])\n",
    "model.fit(train_data[feature_cols], train_data[target_col])\n",
    "\n",
    "c = np.abs(model['clf'].coef_)\n",
    "valid_probas = model.predict_proba(valid_data[feature_cols])[:,1]\n",
    "test_probas = model.predict_proba(test_data[feature_cols])[:,1]\n",
    "print(f'coef_: {c.min():.3f} (min), {c.max():.3f} (max), {(c==0).sum()} / {len(c[0])} (zeros)')\n",
    "print('roc_auc_score (valid): ', roc_auc_score(valid_data[target_col], valid_probas))\n",
    "print('roc_auc_score (test): ', roc_auc_score(test_data[target_col], test_probas))\n",
    "\n",
    "data = prepare_data(pd.read_csv('./test.csv'), train=False)\n",
    "submission = pd.read_csv('./submission.csv')\n",
    "submission['Churn'] = model.predict_proba(data[feature_cols])[:,1]\n",
    "submission.to_csv('./my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "id": "partial-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all features, drop='first', C=100000, penalty='l2'\n",
    "# with outliers, C=10000000, penalty='l2'\n",
    "# with outliers, C=0.4, penalty='l1'\n",
    "# C=1000, penalty='l1'\n",
    "# with outliers, C=1, penalty='l2' 0.8591780061094142 / 0.8564148847542349\n",
    "# with outliers, C=0.33, penalty='l1' 0.8621239470517449 / 0.8579098398592981\n",
    "# C=100000, penalty='l1' 0.8515544284775054 / 0.852812998966845\n",
    "# no replacing zeros, no removing outliers, C=0.4, penalty='l1' 0.862054521892067 / 0.8577848745718781\n",
    "# with outliers, without 'Sex','HasPartner','HasDeviceProtection', C=0.33, penalty='l1', solver='liblinear' \n",
    "# 0.8623530500786818 / 0.8580741460705361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "emotional-shield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClientPeriod bins: [1.0, 2.0, 5.0, 10.0, 17.0, 25.0, 34.0, 44.0, 53.0, 62.0, 70.0, 72.0]\n",
      "MonthlySpending bins: [18.25, 21.1, 50.4, 70.35, 83.9, 96.1, 118.75]\n",
      "TotalSpent bins: [18.8, 198.2, 679.0999999999999, 1400.55, 2754.2999999999997, 4917.8, 8684.8]\n"
     ]
    }
   ],
   "source": [
    "# Cutting numeric features into bins\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "data = pd.concat([train, test]).reset_index()\n",
    "data['TotalSpent'] = pd.to_numeric(data['TotalSpent'], errors='coerce')\n",
    "data['TotalSpent'] = data['TotalSpent'].fillna(0)\n",
    "data['TotalSpent'] = data.groupby('HasContractPhone')['TotalSpent'].apply(lambda x: x.replace(0, x.median()))\n",
    "data['ClientPeriod'] = data.groupby('HasContractPhone')['ClientPeriod'].apply(lambda x: x.replace(0, x.median()))\n",
    "_, period_bins = pd.qcut(data['ClientPeriod'], 11, retbins=True)\n",
    "_, spending_bins = pd.qcut(data['MonthlySpending'], 6, retbins=True)\n",
    "_, spent_bins = pd.qcut(data['TotalSpent'], 6, retbins=True)\n",
    "print('ClientPeriod bins:', period_bins.tolist())\n",
    "print('MonthlySpending bins:', spending_bins.tolist())\n",
    "print('TotalSpent bins:', spent_bins.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
