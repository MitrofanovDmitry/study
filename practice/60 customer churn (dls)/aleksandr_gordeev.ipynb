{"cells":[{"metadata":{"id":"TK7oX5qdEEYr"},"cell_type":"markdown","source":"<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500 height=450/></p>\n\n<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n\n<h3 style=\"text-align: center;\"><b>Домашнее задание. Продвинутый поток. Весна 2021</b></h3>\n\nЭто домашнее задание будет посвящено полноценному решению задачи машинного обучения."},{"metadata":{"id":"IrDNNkNTEEYz"},"cell_type":"markdown","source":"# Первая часть. Исследование"},{"metadata":{"id":"lzLqEeZKEEYz","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve\nimport pandas as pd\nimport numpy as npz\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn import set_config \nset_config(display='diagram')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\nfrom sklearn import pipeline\nfrom sklearn import preprocessing\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline as imb_make_pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Функции"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cv_curve(param_name, mean_test, std_test, mean_train, std_train, param_val, x_type, param_scale=\"log\"):\n    #try:\n    #    param_val.sort()\n    #except:\n    #    pass\n    lower_b_tt = mean_test - 2*std_test\n    upper_b_tt= mean_test + 2*std_test\n    \n    lower_b_tn = mean_train - 2*std_train\n    upper_b_tn = mean_train + 2*std_train\n    \n    f = plt.figure(figsize=(13,5))\n    plt.title('choose ' + param_name)\n    \n    if x_type == 'O':\n        plt.plot(range(len(param_val)), mean_test, label='test mean values of score', color='r', lw=3)\n        plt.plot(range(len(param_val)), lower_b_tt, label='test lower bound', color='b', lw=2, linestyle='dashed')\n        plt.plot(range(len(param_val)), upper_b_tt, label='test upper bound', color='b', lw=2, linestyle='dashed')\n        plt.xticks(range(len(param_val)), param_val)\n\n        plt.plot(range(len(param_val)), mean_train, label='train mean values of score', color='gray', lw=1)\n        plt.plot(range(len(param_val)), lower_b_tn, label='train lower bound', color='gray', lw=1, linestyle='dashed')\n        plt.plot(range(len(param_val)), upper_b_tn, label='train upper bound', color='gray', lw=1, linestyle='dashed')\n        plt.xticks(range(len(param_val)), param_val)\n    else:\n        if param_scale =='log':\n            plt.xscale('log')\n        plt.plot(param_val, mean_test, label='test mean values of score', color='r', lw=3)\n        plt.plot(param_val, lower_b_t, label='lower bound', color='b', lw=2, linestyle='dashed')\n        plt.plot(param_val, upper_b_t, label='upper bound', color='b', lw=2, linestyle='dashed')\n    legend_box = plt.legend(framealpha=1).get_frame()\n    legend_box.set_facecolor('white')\n    legend_box.set_edgecolor('red')\n    plt.xlabel('parameter')\n    plt.ylabel('roc_auc')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def func_roc_auc(proba, y):\n    sns.set(style=\"whitegrid\", palette='Dark2')\n    \n    auc = roc_auc_score(np.array(y), np.transpose(proba)[1])\n    print(f'Лучшее качество auc_best_estimator: {auc:.3}')\n    \n    fpr, tpr, _ = roc_curve(y, proba[:,1])\n    \n    f = plt.figure()\n    plt.plot(fpr, tpr, label = 'best_estimator')\n    plt.plot([0, 1], [0, 1], '--', color = 'grey', label = 'random')\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve')\n    plt.legend(loc = \"lower right\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def matthews_cc(contingency_table):\n    \n    a_1 = contingency_table.iloc[0,0]\n    b_2 = contingency_table.iloc[0,1]\n    c_3 = contingency_table.iloc[1,0]\n    d_4 = contingency_table.iloc[1,1]\n    n = contingency_table.sum().sum()\n    \n    if n <= 40:\n        return print('not enough observations')    \n    \n    con_1 = ((a_1 + c_3) * (a_1 + b_2)) / n\n    con_2 = ((a_1 + c_3) * (c_3 + d_4)) / n\n    con_3 = ((b_2 + d_4) * (a_1 + b_2)) / n\n    con_4 = ((b_2 + d_4) * (c_3 + d_4)) / n\n    \n    if (con_1 or con_2 or con_3 or con_4) < 5:\n        return print('wrong density of distribution')\n    \n    cont = stats.chi2_contingency(contingency_table)\n    # считаем кооэффициент корреляции\n    MCC = (a_1 * d_4 - b_2 * c_3) / (np.sqrt((a_1 + b_2) * (a_1 + c_3) * (b_2 + d_4) * (c_3 + d_4)))\n    # считаем статистику\n    Chi_square = n * (MCC ** 2) \n    # считаем p-value для коэффициента\n    p_value = 1 - stats.chi2.cdf(Chi_square, df = 1)\n    #'cont =', cont, '\\n',\n    return print( 'MCC =', MCC, '\\n', 'Chi_square =', Chi_square, '\\n', 'p_value =', p_value)\n\ndef cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n    rcorr = r-((r-1)**2)/(n-1)\n    kcorr = k-((k-1)**2)/(n-1)\n    return print(f\"Коэф-т Крамера: {np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"LOlxdURSEEY3"},"cell_type":"markdown","source":"## Загрузка данных (2 балла)"},{"metadata":{"id":"KgnkkF5bEEY9","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/advanced-dls-spring-2021/train.csv')\n\nnum_cols = ['ClientPeriod','MonthlySpending', 'TotalSpent']\n\ncat_cols = ['Sex','IsSeniorCitizen','HasPartner','HasChild','HasPhoneService','HasMultiplePhoneNumbers',\n            'HasInternetService','HasOnlineSecurityService','HasOnlineBackup','HasDeviceProtection',\n            'HasTechSupportAccess','HasOnlineTV','HasMovieSubscription','HasContractPhone','IsBillingPaperless',\n            'PaymentMethod']\n\nfeature_cols = num_cols + cat_cols\ntarget_col = 'Churn'\n\n# Переводим TotalSpent в формат флоат. \n# Заполняем для новых пользователей колонку TotalSpent 0\ndata.loc[data[\"ClientPeriod\"] == 0, [\"TotalSpent\"]] = 0\ndata.loc[:, \"TotalSpent\"] = data.loc[:, \"TotalSpent\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"dK370bPCEEZD"},"cell_type":"markdown","source":"## Анализ данных (3 балла)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"whitegrid\", palette='Dark2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выбросы в численных признаках отсутствуют\nf, axes = plt.subplots(1,2, figsize=(10,3))\ndata.loc[:, num_cols[0:2]].boxplot(ax=axes[0])\ndata.loc[:, num_cols[2:]].boxplot(ax=axes[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 8))\n\nfor idx, feat in enumerate(num_cols):\n    sns.boxplot(x='Churn', y=feat, data=data, ax=axes[idx])\n    axes[idx].set_xlabel('Churn')\n    axes[idx].set_ylabel(feat);\n    \n# На первый взгляд кажется, что \n# Во-первых, вероятность уйти выше у новых пользователей\n# Во-вторых, пользователи, склонные к отттоку, в среднем на ежемесячной основе платят больше \n# Ну и, следовательно, учитывая тот факт, что новые пользователя склонны утекать, \n# вполне логично, что в среднем у тех, кто ушел, общие расходы ниже тех, кто остался","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на распределение данных\nsns.pairplot(data.loc[:, ['ClientPeriod', 'MonthlySpending', 'TotalSpent', \"Churn\"]], hue=\"Churn\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим наличие линейных зависимостей в данных\ncorr_matrix = data.loc[:, ['Churn']+num_cols].corr()\nf, ax = plt.subplots(figsize=(15,7))\nsns.heatmap(corr_matrix, vmin=-1, vmax=1, linewidths=0.5, cmap = 'vlag', annot=True)\nplt.yticks(rotation = 0)\nplt.show()\n\n# Как и ожидалось наблюдается сильная линейная зависимость у показателей ClientPeriod и TotalSpent ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заметим, что классы слегка несбалансированы\n# Ради тренировки будем балансировать их с помощью SMOTE в LR\nfig = plt.figure(figsize=(10,5))\nsns.countplot(x=\"Churn\", data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Распрделение категориальных фич\nfor k in range(0,16,3):\n    fig, axes = plt.subplots(1, 3, figsize=(15,4))\n    for i, column in enumerate(cat_cols[k:k+3]):\n        axes = axes.ravel()\n        sns.countplot(x=column, hue='Churn', data=data, ax=axes[i])\n        if k != 15:\n            axes[i].tick_params(axis='x', labelrotation=1)\n        else:\n            axes[i].tick_params(axis='x', labelrotation=50)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Проверим гипотезы о наличии связи между категориальными колонками и оттоком\nfrom scipy import stats\nfor column in cat_cols:\n    cross = pd.crosstab(data.Churn, data[column])\n    print(f\"Корреляция Churn c {column}\")\n    if data[column].value_counts().index.shape[0] == 2:\n        matthews_cc(cross)\n    else:\n        cramers_v(data.Churn, data[column])\n    print(\"\\n\")\n    \n# Sex и HasPhoneService не связаны с Churn, в логрегрессии их использовать смысла нет","execution_count":null,"outputs":[]},{"metadata":{"id":"DviiJd8REEZK"},"cell_type":"markdown","source":"## Применение линейных моделей (3 балла)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Загрзим еще раз данные, чтобы каждый блок можно было запускать отдельно\ndata = pd.read_csv('/kaggle/input/advanced-dls-spring-2021/train.csv')\n\n# Переводим TotalSpent в формат флоат. \n# Заполняем для новых пользователей колонку TotalSpent 0\ndata.loc[data[\"ClientPeriod\"] == 0, [\"TotalSpent\"]] = 0\ndata.loc[:, \"TotalSpent\"] = data.loc[:, \"TotalSpent\"].astype(float)\n\n# Распределим названия колонок\nbinary_data_columns_lr = ['IsSeniorCitizen', 'HasPartner', 'HasChild', 'IsBillingPaperless']\nnumeric_data_columns_lr =  ['ClientPeriod','MonthlySpending']\ncategorical_data_columns_lr = ['HasMultiplePhoneNumbers','HasInternetService','HasOnlineSecurityService',\n                               'HasOnlineBackup','HasDeviceProtection','HasTechSupportAccess','HasOnlineTV',\n                               'HasMovieSubscription','HasContractPhone','PaymentMethod']\n\n# Удалим неинформативные фичи, выявленные в ходе анализа\nx_train_lr = data.drop(columns=[\"Sex\",\"HasPhoneService\", \"TotalSpent\", \"Churn\"])\ny_train = data.loc[:, [\"Churn\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определяем ЛогРег\nregressor = LogisticRegression(random_state=42, C=0.01, penalty=\"l2\", solver=\"lbfgs\")\n\n# Определим SMOTE\nsm = SMOTE(random_state=123, k_neighbors=4)\n\n# Определяем Пайплайн для GridSearchCV.\nestimator_lr = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns_lr])),\n                ('labelencoder', preprocessing.OrdinalEncoder())])),\n                    \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns_lr])),\n                ('scaling', StandardScaler())])),            \n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns_lr])),\n                ('label', preprocessing.OrdinalEncoder()),\n                ('hot_encoding', preprocessing.OneHotEncoder())])),\n        ])),\n    ('SMOTE', sm),\n    ('model_fitting', regressor), \n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определяем сеть поиска\nparam_grid = {\n    'feature_processing__numeric_variables_processing__scaling': [StandardScaler(), RobustScaler(), MinMaxScaler()],\n    'model_fitting__penalty': [\"l1\", \"l2\"],\n    'model_fitting__C': [0.001, 0.01, 0.1, 1, 2],\n    'model_fitting__solver': ['liblinear','lbfgs','saga']\n}\n\n# Определяем Поиск по сети\nclf = GridSearchCV(estimator_lr, \n                   param_grid=param_grid, \n                   scoring='roc_auc', \n                   cv = 4, \n                   return_train_score=True \n                  )\n\n# Обучаем clf\nclf.fit(x_train_lr, y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Рисуем кривые валидации \nrs_df = pd.DataFrame(clf.cv_results_).sort_values('rank_test_score').reset_index(drop=True)\nrs_df.drop(columns = ['mean_fit_time', 'std_fit_time', 'mean_score_time','std_score_time', 'params', \n                      'split0_test_score', 'split1_test_score', 'split2_test_score','split3_test_score',\n                      'split0_train_score', 'split1_train_score', \n                      'split2_train_score', 'split3_train_score'], inplace=True)\nrs_df.dropna(inplace=True)\n\nfor element in list(param_grid.keys()):\n   \n    table = rs_df.loc[:, [\"param_\"+element, \"mean_test_score\", \"std_test_score\", \"mean_train_score\", \"std_train_score\"]]\n    if table[\"param_\"+element].dtype == \"O\":\n        table[\"param_\"+element] = table[\"param_\"+element].astype(str)\n    table.sort_values(\"param_\"+element, inplace=True)\n    param_val = table[\"param_\"+element].drop_duplicates().values\n    mean_test, std_test, mean_train, std_train = table.groupby(\"param_\"+element).mean().values.T\n    cv_curve(param_name = element, mean_test=mean_test, std_test=std_test,\n             mean_train=mean_train, std_train=std_train, param_val=param_val, x_type = param_val.dtype)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Итог по качеству:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Лучшее параметры\nclf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"func_roc_auc(proba=clf.best_estimator_.predict_proba(x_train_lr), y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"BlTeVy7fEEZR"},"cell_type":"markdown","source":"## Применение градиентного бустинга (2 балла)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/advanced-dls-spring-2021/train.csv')\n\n# Переводим TotalSpent в формат флоат. \n# Заполняем для новых пользователей колонку TotalSpent 0\ndata.loc[data[\"ClientPeriod\"] == 0, [\"TotalSpent\"]] = 0\ndata.loc[:, \"TotalSpent\"] = data.loc[:, \"TotalSpent\"].astype(float)\n\n# Распределим названия колонок\nbinary_data_columns_cbc = [\"Sex\", 'IsSeniorCitizen', 'HasPartner', 'HasChild', 'IsBillingPaperless']\nnumeric_data_columns_cbc =  ['ClientPeriod','MonthlySpending', 'TotalSpent']\ncategorical_data_columns_cbc = ['HasMultiplePhoneNumbers','HasInternetService','HasOnlineSecurityService',\n                               'HasOnlineBackup','HasDeviceProtection','HasTechSupportAccess','HasOnlineTV',\n                               'HasMovieSubscription','HasContractPhone','PaymentMethod']\n\n# Удалим неинформативные фичи, выявленные в ходе анализа\nx_train_cbc = data.drop(columns=[\"Churn\"])\nx_train_cbc = x_train_cbc.loc[:, binary_data_columns_cbc+categorical_data_columns_cbc+numeric_data_columns_cbc]\ny_train = data.loc[:, [\"Churn\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sp, X_test_sp, y_train_sp, y_test_sp = train_test_split(x_train_cbc, y_train,\n                                                                test_size=0.2, random_state=42, stratify=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Используем гридсерч, но не встроенный, а из sklearn, так как добавим полиномы для числовых фич в пайплайн\n# Так как используем гридсерч, делить на трейн/тест смысла нет","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(cat_features=np.arange(0,15), task_type=\"GPU\",\n                          learning_rate=0.08, depth=5, l2_leaf_reg=5, iterations=90, logging_level=\"Silent\", \n                          auto_class_weights = \"SqrtBalanced\", loss_function = \"Logloss\")\n\n# Определяем Пайплайн\nestimator_cbc = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns_cbc]))])),\n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n            ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns_cbc]))])),\n        \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns_cbc])),\n                ('poly', preprocessing.PolynomialFeatures(2))])),            \n        \n        ])),\n    ('model_fitting', model), \n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"grid = {\n        'model_fitting__learning_rate' : [0.07, 0.08, 0.09],\n        'model_fitting__depth'         : [4, 5, 6],\n        'model_fitting__l2_leaf_reg'   : [4, 5, 6], \n        'model_fitting__iterations'    : [100, 110, 120], \n        'model_fitting__loss_function' : [\"CrossEntropy\", \"Logloss\"],\n        'model_fitting__auto_class_weights': [\"SqrtBalanced\", \"Balanced\"]\n        }\n\n# Определяем Поиск по сети\ncbc = GridSearchCV(estimator_cbc, \n                   param_grid=grid, \n                   scoring='roc_auc', \n                   cv=4,\n                   return_train_score=True)\n\n# Обучаем estimator\ncbc.fit(x_train_cbc, y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Рисуем кривые валидации \nrs_df = pd.DataFrame(cbc.cv_results_).sort_values('rank_test_score').reset_index(drop=True)\nrs_df.drop(columns = ['mean_fit_time', 'std_fit_time', 'mean_score_time','std_score_time', 'params', \n                      'split0_test_score', 'split1_test_score', 'split2_test_score','split3_test_score',\n                      'split0_train_score', 'split1_train_score', \n                      'split2_train_score', 'split3_train_score'], inplace=True)\nrs_df.dropna(inplace=True)\n\nfor element in list(grid.keys()):\n   \n    table = rs_df.loc[:, [\"param_\"+element, \"mean_test_score\", \"std_test_score\", \"mean_train_score\", \"std_train_score\"]]\n    if table[\"param_\"+element].dtype == \"O\":\n        table[\"param_\"+element] = table[\"param_\"+element].astype(str)\n    table.sort_values(\"param_\"+element, inplace=True)\n    param_val = table[\"param_\"+element].drop_duplicates().values\n    mean_test, std_test, mean_train, std_train = table.groupby(\"param_\"+element).mean().values.T\n    cv_curve(param_name = element, mean_test=mean_test, std_test=std_test,\n             mean_train=mean_train, std_train=std_train, param_val=param_val, x_type = param_val.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Лучшее параметры\ncbc.best_params_\n\n\n# Параметры подобрал не оч хорошие, посмотрите в других ноутбуках, там лучше\n#{'model_fitting__depth': 5,\n# 'model_fitting__iterations': 80,\n# 'model_fitting__l2_leaf_reg': 5,\n# 'model_fitting__learning_rate': 0.08}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(cat_features=np.arange(0,15),\n                          learning_rate=0.08, depth=5, l2_leaf_reg=5, iterations=80, logging_level=\"Silent\", \n                          auto_class_weights = \"Balanced\", loss_function = \"Logloss\")\n\n# Определяем Пайплайн\nestimator_cbc = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns_cbc]))])),\n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n            ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns_cbc]))])),\n        \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns_cbc])),\n                ('poly', preprocessing.PolynomialFeatures(4))])),            \n        \n        ])),\n    ('model_fitting', model), \n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator_cbc.fit(X_train_sp, y_train_sp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"func_roc_auc(proba=estimator_cbc.predict_proba(X_test_sp), y=y_test_sp)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Стекинг"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/advanced-dls-spring-2021/train.csv')\n\n# Переводим TotalSpent в формат флоат. \n# Заполняем для новых пользователей колонку TotalSpent 0\ndata.loc[data[\"ClientPeriod\"] == 0, [\"TotalSpent\"]] = 0\ndata.loc[:, \"TotalSpent\"] = data.loc[:, \"TotalSpent\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(columns=[\"Churn\"])\ny = data.loc[:, [\"Churn\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_data_columns = ['IsSeniorCitizen', 'HasPartner', 'HasChild', 'IsBillingPaperless']\nnumeric_data_columns =  ['ClientPeriod','MonthlySpending', 'TotalSpent']\ncategorical_data_columns = ['HasMultiplePhoneNumbers','HasInternetService','HasOnlineSecurityService',\n                               'HasOnlineBackup','HasDeviceProtection','HasTechSupportAccess','HasOnlineTV',\n                               'HasMovieSubscription','HasContractPhone','PaymentMethod']\n\n\n# Распределим названия колонок\nbinary_data_columns_lr = ['IsSeniorCitizen', 'HasPartner', 'HasChild', 'IsBillingPaperless']\nnumeric_data_columns_lr =  ['ClientPeriod','MonthlySpending']\ncategorical_data_columns_lr = ['HasMultiplePhoneNumbers','HasInternetService','HasOnlineSecurityService',\n                               'HasOnlineBackup','HasDeviceProtection','HasTechSupportAccess','HasOnlineTV',\n                               'HasMovieSubscription','HasContractPhone','PaymentMethod']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определяем ЛогРег\nregressor = LogisticRegression(random_state=42, C=0.01, penalty=\"l2\", solver=\"lbfgs\")\n\n# Определим SMOTE\nsm = SMOTE(random_state=123, k_neighbors=4)\n\n# Определяем Пайплайн\nestimator_lr = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns_lr])),\n                ('labelencoder', preprocessing.OrdinalEncoder())])),\n                    \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns_lr])),\n                ('scaling', StandardScaler())])),            \n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns_lr])),\n                ('label', preprocessing.OrdinalEncoder()),\n                ('hot_encoding', preprocessing.OneHotEncoder())])),\n        ])),\n    ('SMOTE', sm),\n    ('model_fitting', regressor), \n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(cat_features=np.arange(0,14),\n                          learning_rate=0.08, depth=5, l2_leaf_reg=5, iterations=80,\n                          logging_level=\"Silent\", auto_class_weights = \"SqrtBalanced\")\n\n# Определяем Пайплайн\nestimator_cbc = imb_make_pipeline(steps = [       \n    ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n            #binary\n            ('binary_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, binary_data_columns]))])),\n        \n            #categorical\n            ('categorical_variables_processing', pipeline.Pipeline(steps = [\n            ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, categorical_data_columns]))])),\n        \n            #numeric\n            ('numeric_variables_processing', pipeline.Pipeline(steps = [\n                ('selecting', preprocessing.FunctionTransformer(lambda dataset: dataset.loc[:, numeric_data_columns])),\n                ('poly', preprocessing.PolynomialFeatures(2))])),            \n        \n        ])),\n    ('model_fitting', model), \n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\n\nestimators = [\n     ('cbc', estimator_cbc),\n     ('lrc', estimator_lr) ]\n\nstckg = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=42, C=0.03, penalty=\"l2\"))\n\nstckg.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Рисуем качество \nproba_stckg = stckg.predict_proba(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ничего хорошего не получилось :D\nfunc_roc_auc(proba=proba_stckg, y=y)","execution_count":null,"outputs":[]},{"metadata":{"id":"dDMXbvNZEEZV"},"cell_type":"markdown","source":"# Предсказания"},{"metadata":{"id":"FfSufx0CEEZZ","trusted":false},"cell_type":"code","source":"# Логрег ~0,846\n# catboost ~0.854\n# стекинг ~0.85","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}