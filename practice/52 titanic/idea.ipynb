{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://neurohive.io/ru/osnovy-data-science/razbor-resheniya-zadachi-titanik-na-kaggle-dlya-nachinajushhih/  \n",
    "https://github.com/sumitmukhija/Titanic/blob/master/Tip%20of%20the%20Iceberg.ipynb  \n",
    "https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83/notebook  \n",
    "https://github.com/ramansah/kaggle-titanic/blob/master/Analysis.ipynb  \n",
    "https://www.kaggle.com/startupsci/titanic-data-science-solutions  \n",
    "https://www.kaggle.com/makarevich/missing-values-that-you-can-t-miss-in-titanic  \n",
    "https://www.kaggle.com/vradore/titanic-survival-analysis-with-missing-values  \n",
    "https://www.kaggle.com/c/titanic/discussion/62321  \n",
    "https://www.kaggle.com/jack89roberts/titanic-using-ticket-groupings  \n",
    "http://rstudio-pubs-static.s3.amazonaws.com/227239_a42941af5d7d457398ed3721f9ad0f6f.html  \n",
    "https://www.encyclopedia-titanica.org/titanic-victims/  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. использовать все категории (mr, miss...)\n",
    "2. группировать по sex и title\n",
    "3. title как фича\n",
    "4. убрать sibs и parch\n",
    "5. get_dummies - отдельная функция\n",
    "6. заполнять пропуски по всем данным - train + test\n",
    "7. family by last_name -> cabin.fillna\n",
    "8. убрать cabin\n",
    "9. NA ticket => crew member\n",
    "10. все женщины и дети в семьях\n",
    "11. label encoder - hash ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].median())\n",
    "train_data['Fare'] = train_data.groupby('Ticket')['Fare'].transform(lambda x: x / len(x))\n",
    "train_data['Family'] = train_data['SibSp'] + train_data['Parch']\n",
    "sns.histplot(np.log1p(train_data['Fare']));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "m = LogisticRegression()\n",
    "grid = {'C':[0.001,0.01,0.1,1,10,100,1000],'penalty':['l1','l2'],'solver': ['liblinear']}\n",
    "cv = GridSearchCV(m, grid, scoring='accuracy', cv=3)\n",
    "cv.fit(X_train, y_train)\n",
    "cv.best_estimator_, cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler, scaled = MinMaxScaler(), ['SibSp','Parch']\n",
    "# X_train[scaled] = scaler.fit_transform(X_train[scaled])\n",
    "# X_test[scaled] = scaler.transform(X_test[scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = LabelEncoder()\n",
    "# df['Fare'] = label.fit_transform(df['Fare'])\n",
    "# df['Sex'] = label.fit_transform(df['Sex'])\n",
    "# df['Ticket'] = label.fit_transform(df['Ticket'])\n",
    "# df['Age'] = label.fit_transform(df['Age'])\n",
    "# df['Embarked'] = label.fit_transform(df['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_len = len(train_data)\n",
    "df = pd.concat([train_data, test_data])\n",
    "df['Ticket'] = df.groupby(['Ticket']).ngroup()\n",
    "df['Ticket'] = df.groupby('Ticket')['Ticket'].transform(lambda x: -1 if len(x) < 3 else x)\n",
    "df.sort_values(by='Ticket')\n",
    "len(df['Ticket'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_len = len(train_data)\n",
    "df = pd.concat([train_data, test_data])\n",
    "df['Last_Name'] = df['Name'].str.split(\",\").str.get(0)\n",
    "df['Family'] = df.groupby(['Ticket','Last_Name']).ngroup()\n",
    "df['Family'] = df.groupby('Family')['Family'].transform(lambda x: -1 if len(x) < 3 else x)\n",
    "df.sort_values(by='Family')\n",
    "len(df['Family'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_len = len(train_data)\n",
    "df = pd.concat([train_data, test_data])\n",
    "df['Ticket'] = df.groupby('Ticket')['Ticket'].transform(lambda x: '< 3' if len(x) < 3 else x)\n",
    "df.sort_values(by='Ticket')\n",
    "len(df['Ticket'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "df = pd.concat([train_data, test_data])\n",
    "\n",
    "for name, group in df.groupby(['Ticket']):\n",
    "    if len(group) > 1: \n",
    "        print(group[['Cabin','Ticket','Survived']])\n",
    "        print(len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_len = len(train_data)\n",
    "df = pd.concat([train_data, test_data])\n",
    "df['Last_Name'] = df['Name'].str.split(\",\").str.get(0)\n",
    "\n",
    "for name, group in df.groupby(['Ticket','Last_Name']):\n",
    "    if len(group) > 1: \n",
    "        print(group[['Last_Name','Cabin','Ticket','Survived']])\n",
    "        print(len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Ticket'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Family'] = df['SibSp'] + df['Parch']\n",
    "# df['Alone'] = (df['SibSp'] + df['Parch'] == 0).astype(int)\n",
    "# df['Cabin'] = df['Cabin'].fillna('NA')\n",
    "# df['Family'] = df.groupby(['Ticket','Last_Name']).ngroup()\n",
    "# df['Family'] = df.groupby('Family')['Family'].transform(lambda x: -1 if len(x) < 3 else x)\n",
    "# df['Ticket'] = df.groupby(['Ticket']).ngroup()\n",
    "# df['Ticket'] = df.groupby('Ticket')['Ticket'].transform(lambda x: -1 if len(x) < 3 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_len = len(train_data)\n",
    "df = pd.concat([train_data, test_data])\n",
    "df['Last_Name'] = df['Name'].str.split(\",\").str.get(0)\n",
    "\n",
    "for name, group in df.groupby(['Pclass','Last_Name']):\n",
    "    if len(group) > 9: \n",
    "        print(group[['Last_Name','Cabin','Ticket']])\n",
    "        print(len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = ['Pclass','Sex','Age','SibSp','Parch','Cabin','Embarked','Fare','Alone']\n",
    "X_train = pd.get_dummies(X_train, columns=one_hot_encoded)\n",
    "X_test = pd.get_dummies(X_test, columns=one_hot_encoded)\n",
    "X_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('titanic.csv')\n",
    "df2 = pd.read_csv('test.csv')\n",
    "df1 = df1.drop(['Boat','Body','Home.dest'], axis=1)\n",
    "df = pd.concat([df1, df2])\n",
    "df = df[df.duplicated(['Name'], keep=False)]\n",
    "df = df.sort_values(by='Name')\n",
    "df = df[df['Survived'].notnull()]\n",
    "df.to_csv('my_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('titanic.csv')\n",
    "df2 = pd.read_csv('train.csv')\n",
    "df3 = pd.read_csv('test.csv')\n",
    "df4 = pd.concat([df1,df2]).drop_duplicates(subset='Name', keep=\"last\")\n",
    "df1.shape, df2.shape, df3.shape, df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "m = LogisticRegression()\n",
    "grid = {'C':[0.001,0.01,0.1,1,10,100,1000],'penalty':['l1','l2'],'solver': ['liblinear']}\n",
    "cv = GridSearchCV(m, grid, scoring='accuracy', cv=3)\n",
    "cv.fit(X_train, y_train)\n",
    "cv.best_estimator_, cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Name'].str.contains('Don').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data['Fare'] / (train_data['SibSp'] + train_data['Parch'] + 1) < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Pclass'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.groupby('Sex').apply(lambda x: x['Survived'].sum() / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Survived[train_data['Sex'] == 'male'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Survived[train_data['Sex'] == 'female'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['Sex'] == 'male', 'Survived'].mean()\n",
    "train_data.loc[train_data['Sex'] == 'female', 'Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age_c'] = pd.cut(train_data['Age'], 4)\n",
    "# train_data['Age_c'] = pd.cut(train_data['Age'], bins=[0,7.90,14.45,31.28,120])\n",
    "s = train_data.groupby('Age_c').apply(lambda x: x['Survived'].sum() / len(x))\n",
    "plt.bar(s.index.astype(str), s.values)\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women = train_data[train_data['Sex']=='female']\n",
    "men = train_data[train_data['Sex']=='male']\n",
    "# women[women['Survived']==0].Age.dropna().hist()\n",
    "women[women['Survived']==1].Age.dropna().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#women = train_data[train_data['Sex']=='female']\n",
    "#men = train_data[train_data['Sex']=='male']\n",
    "#sns.displot(men[men['Survived']==1].Age.dropna(), bins=18)\n",
    "#sns.displot(men[men['Survived']==0].Age.dropna(), bins=18)\n",
    "#sns.displot(women[women['Survived']==1].Age.dropna(), bins=18)\n",
    "#sns.displot(women[women['Survived']==0].Age.dropna(), bins=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = train_data.groupby('Sex').apply(lambda x: x['Survived'].sum() / len(x))\n",
    "plt.bar(s.index.astype(str), s.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age_c'] = pd.cut(train_data['Age'], 5)\n",
    "train_data.groupby('Age_c').apply(lambda x: x['Survived'].sum() / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = train_data.groupby('Pclass').apply(lambda x: x['Survived'].sum() / len(x))\n",
    "plt.bar(s.index.astype(str), s.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['n'] = train_data.groupby('Ticket')['Fare'].transform(lambda x: len(x))\n",
    "train_data['Fare1'] = train_data.groupby('Ticket')['Fare'].transform(lambda x: x / len(x))\n",
    "train_data['Fare1'] = pd.cut(train_data['Fare1'], bins=[0,10,20,30,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "s = train_data.groupby('Fare1').apply(lambda x: x['Survived'].sum() / len(x))\n",
    "plt.bar(s.index.astype(str), s.values);\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Age'].isnull().sum()\n",
    "# train_data['Title'].isnull().sum()\n",
    "# X['Age'] = X['Age'].fillna(X['Age'].mean())\n",
    "train_data['Title'] = train_data['Name'].str.extract('(Mrs|Mr|Miss)').fillna('NA')\n",
    "train_data['Age'] = train_data.groupby('Title').transform(lambda g: g.fillna(g.mean()))\n",
    "# train_data['Age'] = train_data.groupby('Title')['Age'].apply(lambda g: g.fillna(g.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data\n",
    "X['Title'] = X['Name'].str.extract('([A-Za-z]+)\\.').fillna('NA')\n",
    "# X['Title'] = X['Title'].map({'Mlle':'Miss','Major':'Mr','Col':'Mr','Sir':'Mr','Don':'Mr','Mme':'Miss','Lady':'Mrs','Jonkheer':'Mr','Capt':'Mr','Countess':'Mrs','Ms':'Miss','Dona':'Mrs'})           \n",
    "\n",
    "X['Title'].unique()\n",
    "\n",
    "X['Title'].replace({'Mlle':'Miss','Major':'Mr','Col':'Mr','Sir':'Mr','Don':'Mr','Mme':'Miss','Lady':'Mrs','Jonkheer':'Mr','Capt':'Mr','Countess':'Mrs','Ms':'Miss','Dona':'Mrs'})\n",
    "X['Age'] = X.groupby(['Pclass','Title'])['Age'].transform(lambda g: g.fillna(g.mean()))\n",
    "X['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Age'] = pd.cut(X['Age'], bins=[0,7.90,14.45,31.28,120])\n",
    "X['Fare'] = pd.cut(X['Fare'], bins=[0,10,20,30,100])\n",
    "\n",
    "pd.qcut(train_data['Fare'], 5, labels=[1,2,3,4,5]) # without one hot\n",
    "pd.qcut(train_data['Age'], 4, labels=[1,2,3,4]) # without one hot\n",
    "train_data['Sex'].map({'male':0,'female':1}) # without one hot\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#label = LabelEncoder()\n",
    "#train_data['Fare'] = label.fit_transform(train_data['Fare'])\n",
    "#train_data['Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "train_data['Title'] = train_data['Name'].str.extract('([A-Za-z]+)\\.').fillna('NA')\n",
    "train_data['Title'] = train_data['Title'].replace({'Mlle':'Miss','Major':'Mr','Col':'Mr','Sir':'Mr','Don':'Mr',\n",
    "       'Mme':'Miss','Lady':'Mrs','Jonkheer':'Mr','Capt':'Mr','Countess':'Mrs','Ms':'Miss','Dona':'Mrs'})\n",
    "\n",
    "train_data['Age'] = train_data.groupby(['Pclass','Title'])['Age'].transform(lambda g: g.fillna(g.mean()))\n",
    "train_data['Age'] = pd.cut(train_data['Age'], 10) # bins=[0,7.90,14.45,31.28,120]\n",
    "\n",
    "s = train_data.groupby('Age').apply(lambda x: x['Survived'].sum() / len(x))\n",
    "plt.bar(s.index.astype(str), s.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "\n",
    "y_train = train_data['Survived'].copy()\n",
    "X_train = train_data[['Pclass','Sex','SibSp','Parch','Age','Fare','Embarked','Cabin']].copy()\n",
    "X_test = test_data[['Pclass','Sex','SibSp','Parch','Age','Fare','Embarked','Cabin']].copy()\n",
    "\n",
    "X_train['Age'] = X_train['Age'].fillna(X_train['Age'].mean())\n",
    "X_test['Age'] = X_test['Age'].fillna(X_test['Age'].mean())\n",
    "X_train['Fare'] = X_train['Fare'].fillna(X_train['Fare'].mean())\n",
    "X_test['Fare'] = X_test['Fare'].fillna(X_test['Fare'].mean())\n",
    "X_train['Embarked'] = X_train['Fare'].fillna(X_train['Embarked'].mode()[0])\n",
    "X_test['Embarked'] = X_test['Fare'].fillna(X_test['Embarked'].mode()[0])\n",
    "X_train['Cabin'] = X_train['Cabin'].fillna('NA')\n",
    "X_test['Cabin'] = X_test['Cabin'].fillna('NA')\n",
    "\n",
    "X_train['Family'] = X_train['Parch'] + X_train['SibSp']\n",
    "X_train['Is_Alone'] = (X_train['Family'] == 0)\n",
    "\n",
    "X_train['Age'] = pd.cut(X_train['Age'], 80, labels=range(80))\n",
    "X_test['Age'] = pd.cut(X_test['Age'], 80, labels=range(80))\n",
    "X_train['Fare'] = pd.cut(X_train['Fare'], bins=[0,7.90,14.45,31.28,120], labels=range(4))\n",
    "X_test['Fare'] = pd.cut(X_test['Fare'], bins=[0,7.90,14.45,31.28,120], labels=range(4))\n",
    "\n",
    "# X_train['Sex'] = X_train['Sex'].map({'male':0,'female':1})\n",
    "# X_test['Sex'] = X_test['Sex'].map({'male':0,'female':1})\n",
    "X_train['Sex'] = LabelEncoder().fit_transform(X_train['Sex'])\n",
    "X_test['Sex'] = LabelEncoder().fit_transform(X_test['Sex'])\n",
    "X_train['Embarked'] = LabelEncoder().fit_transform(X_train['Embarked'])\n",
    "X_test['Embarked'] = LabelEncoder().fit_transform(X_test['Embarked'])\n",
    "X_train['Cabin'] = LabelEncoder().fit_transform(X_train['Cabin'])\n",
    "X_test['Cabin'] = LabelEncoder().fit_transform(X_test['Cabin'])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train[['Age']] = scaler.fit_transform(X_train[['Age']])\n",
    "# X_test[['Age']] = scaler.transform(X_test[['Age']])\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train[['Fare']] = scaler.fit_transform(X_train[['Fare']])\n",
    "# X_test[['Fare']] = scaler.transform(X_test[['Fare']])\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=['Pclass','Sex','SibSp','Parch','Age','Fare','Embarked','Cabin'])\n",
    "X_test = pd.get_dummies(X_test, columns=['Pclass','Sex','SibSp','Parch', 'Age', 'Fare','Embarked','Cabin'])\n",
    "X_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "lr = LogisticRegression(C=1, solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = test_data.PassengerId\n",
    "output['Survived'] = lr.predict(X_test)\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "\n",
    "cross_val_score(lr, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "# accuracy_score(y_train, lr.predict(X_train))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l1','l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(lr, grid, scoring='accuracy', cv=3)\n",
    "cv.fit(X_train, y_train)\n",
    "cv.best_estimator_, cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_data['Survived'], train_data['Fare'], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Fare'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.groupby('Fare')['Survived'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = X_test.drop('Parch_9', axis=1)\n",
    "# train_data[train_data['Age'].isnull()]\n",
    "# train_data['Cabin'].unique()\n",
    "# (test_data['Fare'] == 0).sum()\n",
    "# X_train['Age'].mean()\n",
    "# pd.cut(train_data['Age'], 5, labels=[1,2,3,4,5])\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_category(age):\n",
    "    if age < 16: return 1\n",
    "    if age < 35: return 2\n",
    "    return 3\n",
    "\n",
    "# train_data['Age'].apply(age_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def age_category(age):\n",
    "    if age < 18: return 1\n",
    "    if age < 35: return 2\n",
    "    return 3\n",
    "\n",
    "X_train['Age'] = X_train['Age'].apply(age_category)\n",
    "X_test['Age'] = X_test['Age'].apply(age_category)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "\n",
    "features = ['Pclass','Sex','SibSp','Parch']\n",
    "y_train = train_data['Survived'].copy()\n",
    "\n",
    "X_train = train_data[features].copy()\n",
    "X_train['Sex'] = X_train['Sex'].map({'male':0,'female':1})\n",
    "X_train = pd.get_dummies(X_train, columns=features)\n",
    "\n",
    "X_test = test_data[features].copy()\n",
    "X_test['Sex'] = X_test['Sex'].map({'male':0,'female':1})\n",
    "X_test = pd.get_dummies(X_test, columns=features)\n",
    "X_test = X_test.drop('Parch_9', axis=1)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = test_data.PassengerId\n",
    "output['Survived'] = knn.predict(X_test)\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.groupby('Age').size().sort_index().plot()\n",
    "# plt.plot(s.index, s.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.groupby('Sex').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "accuracy_score(y_train, knn.predict(X_train))\n",
    "accuracy_score(y_train, lr.predict(X_train))\n",
    "sns.pairplot(train_data, hue='Survived')\n",
    "plt.scatter(x=train_data['SibSp'], y=train_data['Pclass'])\n",
    "train_data['Sex'].hist()\n",
    "cross_val_score(lr, X_train, y_train, scoring='accuracy', cv=3)\n",
    "confusion_matrix(y_train, lr.predict(X_train))\n",
    "cat my_submission.csv\n",
    "lr.coef_\n",
    "X_train.isnull().sum()\n",
    "X_train.info()\n",
    "X_train = X_train.replace(['male','female'], [0,1])\n",
    "X_train['Sex'] = X_train['Sex'].replace(['male','female'], [0,1])\n",
    "X_train['Sex'] = X_train['Sex'].replace({'male':0,'female':1})\n",
    "X_train['Sex'] = X_train['Sex'].map({'male':0,'female':1})\n",
    "X_train['Sex'] = 1 #X_train['Sex'].apply(lambda x: {'male':0,'female':1}[x])\n",
    "X_train['Sex'].isnull().sum()\n",
    "train_data[:5]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y = train_data[\"Survived\"]\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "\n",
    "y_train = train_data['Survived'].copy()\n",
    "X_train = train_data[['Pclass','Sex','SibSp','Parch','Age','Fare','Embarked','Cabin']].copy()\n",
    "X_test = test_data[['Pclass','Sex','SibSp','Parch','Age','Fare','Embarked','Cabin']].copy()\n",
    "\n",
    "X_train['Age'] = X_train['Age'].fillna(X_train['Age'].mean())\n",
    "X_test['Age'] = X_test['Age'].fillna(X_test['Age'].mean())\n",
    "X_train['Fare'] = X_train['Fare'].fillna(X_train['Fare'].mean())\n",
    "X_test['Fare'] = X_test['Fare'].fillna(X_test['Fare'].mean())\n",
    "X_train['Embarked'] = X_train['Embarked'].fillna(X_train['Embarked'].mode()[0])\n",
    "X_test['Embarked'] = X_test['Embarked'].fillna(X_test['Embarked'].mode()[0])\n",
    "X_train['Cabin'] = X_train['Cabin'].fillna('NA')\n",
    "X_test['Cabin'] = X_test['Cabin'].fillna('NA')\n",
    "\n",
    "X_train['Family'] = X_train['Parch'] + X_train['SibSp']\n",
    "X_train['Is_Alone'] = (X_train['Family'] == 0)\n",
    "\n",
    "X_train['Age'] = pd.cut(X_train['Age'], 80, labels=range(80))\n",
    "X_test['Age'] = pd.cut(X_test['Age'], 80, labels=range(80))\n",
    "X_train['Fare'] = pd.cut(X_train['Fare'], bins=[0,7.90,14.45,31.28,120], labels=range(4))\n",
    "X_test['Fare'] = pd.cut(X_test['Fare'], bins=[0,7.90,14.45,31.28,120], labels=range(4))\n",
    "\n",
    "# X_train['Sex'] = X_train['Sex'].map({'male':0,'female':1})\n",
    "# X_test['Sex'] = X_test['Sex'].map({'male':0,'female':1})\n",
    "X_train['Sex'] = LabelEncoder().fit_transform(X_train['Sex'])\n",
    "X_test['Sex'] = LabelEncoder().fit_transform(X_test['Sex'])\n",
    "X_train['Embarked'] = LabelEncoder().fit_transform(X_train['Embarked'])\n",
    "X_test['Embarked'] = LabelEncoder().fit_transform(X_test['Embarked'])\n",
    "X_train['Cabin'] = LabelEncoder().fit_transform(X_train['Cabin'])\n",
    "X_test['Cabin'] = LabelEncoder().fit_transform(X_test['Cabin'])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train[['Age']] = scaler.fit_transform(X_train[['Age']])\n",
    "# X_test[['Age']] = scaler.transform(X_test[['Age']])\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train[['Fare']] = scaler.fit_transform(X_train[['Fare']])\n",
    "# X_test[['Fare']] = scaler.transform(X_test[['Fare']])\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=['Pclass','Sex','SibSp','Parch','Age','Fare','Embarked','Cabin'])\n",
    "X_test = pd.get_dummies(X_test, columns=['Pclass','Sex','SibSp','Parch', 'Age', 'Fare','Embarked','Cabin'])\n",
    "X_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "lr = LogisticRegression(C=1, solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = test_data.PassengerId\n",
    "output['Survived'] = lr.predict(X_test)\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "\n",
    "cross_val_score(lr, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "# accuracy_score(y_train, lr.predict(X_train))\n",
    "\n",
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
