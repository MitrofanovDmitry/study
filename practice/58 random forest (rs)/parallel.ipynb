{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dangerous-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "quiet-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.outcome_probs = 0\n",
    "    \n",
    "    def fit(self, X, y, n_features=None, max_depth=None):\n",
    "        self.outcome_probs = 7\n",
    "        return self #!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "adult-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "X, y = np.array([1,2]), np.array([3,4])\n",
    "trees_in = [Tree() for _ in range(10)]\n",
    "trees_out = Parallel(n_jobs=2)(delayed(Tree.fit)(tree, X, y) for tree in trees_in)\n",
    "print([tree.outcome_probs for tree in trees_in])\n",
    "print([tree.outcome_probs for tree in trees_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "oriental-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "fit = []\n",
    "X, y = np.array([1,2]), np.array([3,4])\n",
    "trees_in = [Tree() for _ in range(10)]\n",
    "\n",
    "for tree in trees_in:\n",
    "    # bootstrap\n",
    "    fit.append(delayed(Tree.fit)(tree, X, y))\n",
    "\n",
    "trees_out = Parallel(n_jobs=2)(delayed_tree_fit)\n",
    "print([tree.outcome_probs for tree in trees_in])\n",
    "print([tree.outcome_probs for tree in trees_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "published-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "df = pd.read_csv(PATH+'sonar-all-data.csv', header=None)\n",
    "df.columns = [f'feat_{col}' if col!=60 else 'target' for col in df.columns]\n",
    "df['target'] = df['target'].map({'M': 1, 'R': 0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='target'), df['target'], test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "amazing-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(x):   \n",
    "    if len(x) == 0:\n",
    "        return 0.0\n",
    "    p = np.bincount(x) / len(x)\n",
    "    return 1 - np.sum(p*p)\n",
    "\n",
    "def gini_gain(parent_node, splits):   \n",
    "    splits_gini = np.sum([gini_index(split)*(len(split)/len(parent_node)) for split in splits])\n",
    "    return gini_index(parent_node) - splits_gini\n",
    "\n",
    "def entropy(x):\n",
    "    if len(x) == 0:\n",
    "        return 0.0\n",
    "    p = np.clip(np.bincount(x) / len(x), 1e-15, 1.)\n",
    "    return -np.sum(p * np.log(p))\n",
    "\n",
    "def information_gain(parent_node, splits):    \n",
    "    splits_entropy = np.sum([entropy(split)*(len(split)/len(parent_node)) for split in splits])\n",
    "    return entropy(parent_node) - splits_entropy\n",
    "\n",
    "def split(X, y, value):      \n",
    "    left_mask = X < value\n",
    "    right_mask = X >= value\n",
    "    return y[left_mask], y[right_mask]\n",
    "\n",
    "def split_dataset(X, y, column, value):     \n",
    "    left_mask = X[:, column] < value\n",
    "    right_mask = X[:, column] >= value\n",
    "    left_y, right_y = y[left_mask], y[right_mask]\n",
    "    left_X, right_X = X[left_mask], X[right_mask]\n",
    "    return left_X, right_X, left_y, right_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "irish-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "\n",
    "    def __init__(self, criterion=None):\n",
    "        self.impurity = None\n",
    "        self.threshold = None\n",
    "        self.column_index = None\n",
    "        self.outcome_probs = None\n",
    "        self.criterion = criterion\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "\n",
    "    @property\n",
    "    def is_terminal(self):         \n",
    "        return not bool(self.left_child and self.right_child)\n",
    "\n",
    "    def _find_splits(self, X):\n",
    "        split_values = set()\n",
    "        x_unique = list(np.unique(X))\n",
    "        for i in range(1, len(x_unique)):\n",
    "            average = (x_unique[i - 1] + x_unique[i]) / 2.0\n",
    "            split_values.add(average)\n",
    "\n",
    "        return list(split_values)\n",
    "\n",
    "    def _find_best_split(self, X, y, n_features):\n",
    "        subset = random.sample(list(range(0, X.shape[1])), n_features)\n",
    "        max_gain, max_col, max_val = None, None, None\n",
    "        for column in subset:\n",
    "            split_values = self._find_splits(X[:, column])\n",
    "            for value in split_values:\n",
    "                splits = split(X[:, column], y, value)\n",
    "                gain = self.criterion(y, splits)\n",
    "                if (max_gain is None) or (gain > max_gain):\n",
    "                    max_col, max_val, max_gain = column, value, gain\n",
    "        return max_col, max_val, max_gain\n",
    "\n",
    "    def fit(self, X, y, n_features=None, max_depth=None):    \n",
    "        try:\n",
    "            if max_depth is not None:\n",
    "                assert max_depth > 0\n",
    "                max_depth -= 1\n",
    "\n",
    "            if n_features is None:\n",
    "                n_features = X.shape[1]\n",
    "\n",
    "            column, value, gain = self._find_best_split(X, y, n_features)\n",
    "            assert gain is not None\n",
    "\n",
    "            self.column_index = column\n",
    "            self.threshold = value\n",
    "            self.impurity = gain\n",
    "\n",
    "            left_X, right_X, left_target, right_target = split_dataset(X, y, column, value)\n",
    "\n",
    "            self.left_child = Tree(self.criterion)\n",
    "            self.left_child.fit(\n",
    "                left_X, left_target, n_features, max_depth\n",
    "            )\n",
    "\n",
    "            self.right_child = Tree(self.criterion)\n",
    "            self.right_child.fit(\n",
    "                right_X, right_target, n_features, max_depth\n",
    "            )\n",
    "        except AssertionError:\n",
    "            self.outcome_probs = np.around(np.sum(y) / y.shape[0])\n",
    "\n",
    "        return self #@!\n",
    "\n",
    "    def predict_row(self, row):\n",
    "        \n",
    "        if not self.is_terminal:\n",
    "            if row[self.column_index] < self.threshold:\n",
    "                return self.left_child.predict_row(row)\n",
    "            else:\n",
    "                return self.right_child.predict_row(row)\n",
    "        return self.outcome_probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        result = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            result[i] = self.predict_row(X[i, :])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "legislative-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier(object):\n",
    "    \n",
    "    def __init__(self, n_jobs=1, n_estimators=10, max_depth=None, n_features=None, criterion=\"entropy\", bootstrap=True):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.bootstrap = bootstrap\n",
    "        \n",
    "        if criterion == \"entropy\":\n",
    "            self.criterion = information_gain\n",
    "        elif criterion == \"gini\":\n",
    "            self.criterion = gini_gain\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown criterion '{criterion}'\")\n",
    "            \n",
    "        self.trees = [Tree(criterion=self.criterion) for _ in range(n_estimators)]\n",
    "        \n",
    "    def _init_data(self, X, y):\n",
    "\n",
    "        self.size = len(X)\n",
    "        \n",
    "        if not isinstance(X, np.ndarray):\n",
    "            self.X = np.array(X)\n",
    "        else:\n",
    "            self.X = X\n",
    "\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            self.y = np.array(y)\n",
    "        else:\n",
    "            self.y = y\n",
    "            \n",
    "    def bootstrap_data(self, size):\n",
    "        return np.random.randint(size, size=size)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "     \n",
    "        if self.n_features is None:\n",
    "            self.n_features = int(np.sqrt(X.shape[1]))\n",
    "        elif X.shape[1] < self.n_features:\n",
    "            raise ValueError(f\"'n_features should be <= n_features'\")\n",
    "            \n",
    "        self._init_data(X, y)\n",
    "        \n",
    "        #@!\n",
    "        fit = []\n",
    "        for tree in self.trees:\n",
    "            if self.bootstrap:\n",
    "                idxs = self.bootstrap_data(self.size)\n",
    "                X, y = self.X[idxs], self.y[idxs]\n",
    "            else:\n",
    "                X, y = self.X, self.y\n",
    "            if self.n_jobs < 2:\n",
    "                tree.fit(X, y, self.n_features, self.max_depth)\n",
    "            else:\n",
    "                fit.append(delayed(Tree.fit)(tree, X, y, self.n_features, self.max_depth))\n",
    "        if fit: \n",
    "            self.trees = Parallel(n_jobs=self.n_jobs)(fit)\n",
    "        #@!\n",
    "            \n",
    "    def predict(self, X):\n",
    "            \n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "\n",
    "        if self.X is not None:\n",
    "            predictions = np.zeros(len(X))\n",
    "            for i in range(len(X)):\n",
    "                row_pred = 0.\n",
    "                for tree in self.trees:\n",
    "                    row_pred += tree.predict_row(X[i, :])\n",
    "\n",
    "                row_pred /= self.n_estimators\n",
    "                predictions[i] = round(row_pred)\n",
    "            return predictions  \n",
    "        else:\n",
    "            raise ValueError(\"You should fit a model before `predict`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "olympic-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.8095238095238095\n",
      "CPU times: user 6.78 s, sys: 3.74 ms, total: 6.78 s\n",
      "Wall time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(n_jobs=1, n_estimators=10, max_depth=None, n_features=None, criterion=\"entropy\")\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Accuracy score is: {accuracy_score(y_test, model.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "proprietary-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.8095238095238095\n",
      "CPU times: user 73.7 ms, sys: 15.9 ms, total: 89.6 ms\n",
      "Wall time: 3.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(n_jobs=2, n_estimators=10, max_depth=None, n_features=None, criterion=\"entropy\")\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Accuracy score is: {accuracy_score(y_test, model.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "parliamentary-fabric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.8571428571428571\n",
      "CPU times: user 158 ms, sys: 36.1 ms, total: 194 ms\n",
      "Wall time: 3.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(n_jobs=4, n_estimators=10, max_depth=None, n_features=None, criterion=\"entropy\")\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Accuracy score is: {accuracy_score(y_test, model.predict(X_test))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
