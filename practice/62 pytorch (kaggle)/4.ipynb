{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separate-compilation",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/krishanudb/basic-computation-graph-using-pytorch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "valuable-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secondary-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Hyperparameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endless-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Toy Dataset\n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],[9.779], [6.182], [7.59], [2.167], [7.042], [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], [3.366], [2.596], [2.53], [1.221], [2.827], [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chief-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "model = nn.Linear(input_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "associate-viewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000/10000; \tLoss: 0.1699303239583969\n",
      "Epoch: 2000/10000; \tLoss: 0.1695225089788437\n",
      "Epoch: 3000/10000; \tLoss: 0.1692786067724228\n",
      "Epoch: 4000/10000; \tLoss: 0.16913264989852905\n",
      "Epoch: 5000/10000; \tLoss: 0.1690453439950943\n",
      "Epoch: 6000/10000; \tLoss: 0.16899307072162628\n",
      "Epoch: 7000/10000; \tLoss: 0.16896182298660278\n",
      "Epoch: 8000/10000; \tLoss: 0.1689431369304657\n",
      "Epoch: 9000/10000; \tLoss: 0.16893194615840912\n",
      "Epoch: 10000/10000; \tLoss: 0.1689252406358719\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(\"Epoch: {}/{}; \\tLoss: {}\".format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "executive-topic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the outputs\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.scatter(x_train, y_train, label='original data')\n",
    "plt.scatter(x_train, predicted, label='predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exclusive-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "# Defining Hyperparameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naked-driver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# loding the Dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train = False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "convenient-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset.train_data[0], cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "useful-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efficient-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hindu-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, \tIteration: 200/600, \tLoss: 2.104520559310913\n",
      "Epoch: 1/20, \tIteration: 400/600, \tLoss: 1.9826343059539795\n",
      "Epoch: 1/20, \tIteration: 600/600, \tLoss: 1.8069018125534058\n",
      "Epoch: 2/20, \tIteration: 200/600, \tLoss: 1.7149571180343628\n",
      "Epoch: 2/20, \tIteration: 400/600, \tLoss: 1.5796902179718018\n",
      "Epoch: 2/20, \tIteration: 600/600, \tLoss: 1.3905000686645508\n",
      "Epoch: 3/20, \tIteration: 200/600, \tLoss: 1.352664589881897\n",
      "Epoch: 3/20, \tIteration: 400/600, \tLoss: 1.3142096996307373\n",
      "Epoch: 3/20, \tIteration: 600/600, \tLoss: 1.259871006011963\n",
      "Epoch: 4/20, \tIteration: 200/600, \tLoss: 1.2251907587051392\n",
      "Epoch: 4/20, \tIteration: 400/600, \tLoss: 1.1554583311080933\n",
      "Epoch: 4/20, \tIteration: 600/600, \tLoss: 1.0980323553085327\n",
      "Epoch: 5/20, \tIteration: 200/600, \tLoss: 1.1192119121551514\n",
      "Epoch: 5/20, \tIteration: 400/600, \tLoss: 1.0442242622375488\n",
      "Epoch: 5/20, \tIteration: 600/600, \tLoss: 1.0401078462600708\n",
      "Epoch: 6/20, \tIteration: 200/600, \tLoss: 0.8784672021865845\n",
      "Epoch: 6/20, \tIteration: 400/600, \tLoss: 0.9196921586990356\n",
      "Epoch: 6/20, \tIteration: 600/600, \tLoss: 0.9531068205833435\n",
      "Epoch: 7/20, \tIteration: 200/600, \tLoss: 0.9623211622238159\n",
      "Epoch: 7/20, \tIteration: 400/600, \tLoss: 0.8895233273506165\n",
      "Epoch: 7/20, \tIteration: 600/600, \tLoss: 0.8761837482452393\n",
      "Epoch: 8/20, \tIteration: 200/600, \tLoss: 0.7852035760879517\n",
      "Epoch: 8/20, \tIteration: 400/600, \tLoss: 0.7955050468444824\n",
      "Epoch: 8/20, \tIteration: 600/600, \tLoss: 0.886231005191803\n",
      "Epoch: 9/20, \tIteration: 200/600, \tLoss: 0.7229300141334534\n",
      "Epoch: 9/20, \tIteration: 400/600, \tLoss: 0.8666515350341797\n",
      "Epoch: 9/20, \tIteration: 600/600, \tLoss: 0.7224274277687073\n",
      "Epoch: 10/20, \tIteration: 200/600, \tLoss: 0.6974990367889404\n",
      "Epoch: 10/20, \tIteration: 400/600, \tLoss: 0.7379356622695923\n",
      "Epoch: 10/20, \tIteration: 600/600, \tLoss: 0.7849018573760986\n",
      "Epoch: 11/20, \tIteration: 200/600, \tLoss: 0.7146829962730408\n",
      "Epoch: 11/20, \tIteration: 400/600, \tLoss: 0.7461894154548645\n",
      "Epoch: 11/20, \tIteration: 600/600, \tLoss: 0.748472273349762\n",
      "Epoch: 12/20, \tIteration: 200/600, \tLoss: 0.6832996606826782\n",
      "Epoch: 12/20, \tIteration: 400/600, \tLoss: 0.6924384236335754\n",
      "Epoch: 12/20, \tIteration: 600/600, \tLoss: 0.6994976997375488\n",
      "Epoch: 13/20, \tIteration: 200/600, \tLoss: 0.5746400356292725\n",
      "Epoch: 13/20, \tIteration: 400/600, \tLoss: 0.631192147731781\n",
      "Epoch: 13/20, \tIteration: 600/600, \tLoss: 0.7253322005271912\n",
      "Epoch: 14/20, \tIteration: 200/600, \tLoss: 0.6600337028503418\n",
      "Epoch: 14/20, \tIteration: 400/600, \tLoss: 0.6342170238494873\n",
      "Epoch: 14/20, \tIteration: 600/600, \tLoss: 0.5940806865692139\n",
      "Epoch: 15/20, \tIteration: 200/600, \tLoss: 0.5598767399787903\n",
      "Epoch: 15/20, \tIteration: 400/600, \tLoss: 0.7523225545883179\n",
      "Epoch: 15/20, \tIteration: 600/600, \tLoss: 0.6621050834655762\n",
      "Epoch: 16/20, \tIteration: 200/600, \tLoss: 0.6737198829650879\n",
      "Epoch: 16/20, \tIteration: 400/600, \tLoss: 0.5992310047149658\n",
      "Epoch: 16/20, \tIteration: 600/600, \tLoss: 0.6619160175323486\n",
      "Epoch: 17/20, \tIteration: 200/600, \tLoss: 0.572549045085907\n",
      "Epoch: 17/20, \tIteration: 400/600, \tLoss: 0.5763912200927734\n",
      "Epoch: 17/20, \tIteration: 600/600, \tLoss: 0.5934767127037048\n",
      "Epoch: 18/20, \tIteration: 200/600, \tLoss: 0.541531503200531\n",
      "Epoch: 18/20, \tIteration: 400/600, \tLoss: 0.6062994599342346\n",
      "Epoch: 18/20, \tIteration: 600/600, \tLoss: 0.6057134866714478\n",
      "Epoch: 19/20, \tIteration: 200/600, \tLoss: 0.6196805834770203\n",
      "Epoch: 19/20, \tIteration: 400/600, \tLoss: 0.5107129216194153\n",
      "Epoch: 19/20, \tIteration: 600/600, \tLoss: 0.5349079966545105\n",
      "Epoch: 20/20, \tIteration: 200/600, \tLoss: 0.553961992263794\n",
      "Epoch: 20/20, \tIteration: 400/600, \tLoss: 0.7429515719413757\n",
      "Epoch: 20/20, \tIteration: 600/600, \tLoss: 0.5545377135276794\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "total_step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(-1, 28 * 28)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(\"Epoch: {}/{}, \\tIteration: {}/{}, \\tLoss: {}\".format(epoch + 1, num_epochs, i + 1, len(trainloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "burning-mounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8653333333333333\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        images = images.reshape(-1, 28 * 28)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        total += labels.size(0)\n",
    "    print(\"Accuracy of the model: {}\".format(float(correct) / float(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "marine-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward Neural Network Model\n",
    "# Defining the network parameters\n",
    "input_size = 28 * 28\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "random-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader Objects\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "secret-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "owned-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "affected-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "returning-shore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20;\tIteration: 200/600; Loss: 2.262850761413574\n",
      "Epoch: 1/20;\tIteration: 400/600; Loss: 2.2144739627838135\n",
      "Epoch: 1/20;\tIteration: 600/600; Loss: 2.172609806060791\n",
      "Epoch: 2/20;\tIteration: 200/600; Loss: 2.116544246673584\n",
      "Epoch: 2/20;\tIteration: 400/600; Loss: 2.0764412879943848\n",
      "Epoch: 2/20;\tIteration: 600/600; Loss: 1.9877212047576904\n",
      "Epoch: 3/20;\tIteration: 200/600; Loss: 1.9398133754730225\n",
      "Epoch: 3/20;\tIteration: 400/600; Loss: 1.8850815296173096\n",
      "Epoch: 3/20;\tIteration: 600/600; Loss: 1.7898401021957397\n",
      "Epoch: 4/20;\tIteration: 200/600; Loss: 1.6916694641113281\n",
      "Epoch: 4/20;\tIteration: 400/600; Loss: 1.6672512292861938\n",
      "Epoch: 4/20;\tIteration: 600/600; Loss: 1.6237313747406006\n",
      "Epoch: 5/20;\tIteration: 200/600; Loss: 1.5764994621276855\n",
      "Epoch: 5/20;\tIteration: 400/600; Loss: 1.455335259437561\n",
      "Epoch: 5/20;\tIteration: 600/600; Loss: 1.436743140220642\n",
      "Epoch: 6/20;\tIteration: 200/600; Loss: 1.3855292797088623\n",
      "Epoch: 6/20;\tIteration: 400/600; Loss: 1.2550292015075684\n",
      "Epoch: 6/20;\tIteration: 600/600; Loss: 1.1416548490524292\n",
      "Epoch: 7/20;\tIteration: 200/600; Loss: 1.1811758279800415\n",
      "Epoch: 7/20;\tIteration: 400/600; Loss: 1.1086078882217407\n",
      "Epoch: 7/20;\tIteration: 600/600; Loss: 1.0325275659561157\n",
      "Epoch: 8/20;\tIteration: 200/600; Loss: 1.0928690433502197\n",
      "Epoch: 8/20;\tIteration: 400/600; Loss: 0.9827016592025757\n",
      "Epoch: 8/20;\tIteration: 600/600; Loss: 0.9983435869216919\n",
      "Epoch: 9/20;\tIteration: 200/600; Loss: 0.9924092292785645\n",
      "Epoch: 9/20;\tIteration: 400/600; Loss: 0.8056002855300903\n",
      "Epoch: 9/20;\tIteration: 600/600; Loss: 0.850954532623291\n",
      "Epoch: 10/20;\tIteration: 200/600; Loss: 0.8380562663078308\n",
      "Epoch: 10/20;\tIteration: 400/600; Loss: 0.8397927284240723\n",
      "Epoch: 10/20;\tIteration: 600/600; Loss: 0.8430905342102051\n",
      "Epoch: 11/20;\tIteration: 200/600; Loss: 0.720543622970581\n",
      "Epoch: 11/20;\tIteration: 400/600; Loss: 0.657411515712738\n",
      "Epoch: 11/20;\tIteration: 600/600; Loss: 0.6556056141853333\n",
      "Epoch: 12/20;\tIteration: 200/600; Loss: 0.793830394744873\n",
      "Epoch: 12/20;\tIteration: 400/600; Loss: 0.6458313465118408\n",
      "Epoch: 12/20;\tIteration: 600/600; Loss: 0.8193366527557373\n",
      "Epoch: 13/20;\tIteration: 200/600; Loss: 0.8331394791603088\n",
      "Epoch: 13/20;\tIteration: 400/600; Loss: 0.626802384853363\n",
      "Epoch: 13/20;\tIteration: 600/600; Loss: 0.6076183915138245\n",
      "Epoch: 14/20;\tIteration: 200/600; Loss: 0.7156575918197632\n",
      "Epoch: 14/20;\tIteration: 400/600; Loss: 0.6678679585456848\n",
      "Epoch: 14/20;\tIteration: 600/600; Loss: 0.6178093552589417\n",
      "Epoch: 15/20;\tIteration: 200/600; Loss: 0.6129958629608154\n",
      "Epoch: 15/20;\tIteration: 400/600; Loss: 0.5802575349807739\n",
      "Epoch: 15/20;\tIteration: 600/600; Loss: 0.48470538854599\n",
      "Epoch: 16/20;\tIteration: 200/600; Loss: 0.7076053619384766\n",
      "Epoch: 16/20;\tIteration: 400/600; Loss: 0.5390292406082153\n",
      "Epoch: 16/20;\tIteration: 600/600; Loss: 0.6916710138320923\n",
      "Epoch: 17/20;\tIteration: 200/600; Loss: 0.6328569650650024\n",
      "Epoch: 17/20;\tIteration: 400/600; Loss: 0.6131226420402527\n",
      "Epoch: 17/20;\tIteration: 600/600; Loss: 0.41373398900032043\n",
      "Epoch: 18/20;\tIteration: 200/600; Loss: 0.6117215156555176\n",
      "Epoch: 18/20;\tIteration: 400/600; Loss: 0.5396355390548706\n",
      "Epoch: 18/20;\tIteration: 600/600; Loss: 0.4222540259361267\n",
      "Epoch: 19/20;\tIteration: 200/600; Loss: 0.5759475231170654\n",
      "Epoch: 19/20;\tIteration: 400/600; Loss: 0.6310343742370605\n",
      "Epoch: 19/20;\tIteration: 600/600; Loss: 0.5109333395957947\n",
      "Epoch: 20/20;\tIteration: 200/600; Loss: 0.4381095767021179\n",
      "Epoch: 20/20;\tIteration: 400/600; Loss: 0.5244746208190918\n",
      "Epoch: 20/20;\tIteration: 600/600; Loss: 0.5865141153335571\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(\"Epoch: {}/{};\\tIteration: {}/{}; Loss: {}\".format(epoch + 1, num_epochs, i + 1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "digital-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model 0.8808\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        total += labels.size(0)\n",
    "print(\"Accuracy of the model {}\".format(float(correct)/float(total)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
